{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramOriginal(datasetStemmed, vocabularyStemmed):\n",
    "    total = len(datasetStemmed)\n",
    "    count = 0\n",
    "    print('- Unsmoothed -')\n",
    "    for x in vocabularyStemmed:\n",
    "        for y in datasetStemmed:\n",
    "            if(y == x):\n",
    "                count = count + 1\n",
    "        print(\" \" + x + \": \" + str(count/total), end='')\n",
    "        count = 0\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramSmoothed(datasetStemmed, vocabularyStemmed):\n",
    "    total = len(datasetStemmed)\n",
    "    count = 0\n",
    "    print('- Smoothed -'sn)\n",
    "    for x in vocabularyStemmed:\n",
    "        for y in datasetStemmed:\n",
    "            if(y == x):\n",
    "                count = count + 1\n",
    "        print(\" \" + x + \": \" + str((count + 1)/ (total + len(vocabularyStemmed))), end='')\n",
    "        count = 0\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramOriginal(datasetStemmed, vocabularyStemmed):\n",
    "    w, h = 5, 5;\n",
    "    Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "    uniCount = 0\n",
    "    biCount = 0\n",
    "    print('- Unsmoothed -')\n",
    "    assignColumn = 0\n",
    "    for x in vocabularyStemmed:\n",
    "        #count the number of combination that has x in the beginning\n",
    "        for y in datasetStemmed:\n",
    "            if(y[1] == x):\n",
    "                uniCount = uniCount + 1\n",
    "        precedeCount = 0\n",
    "        for precede in vocabularyStemmed:\n",
    "            biCount = 0\n",
    "            if((precede == \"<s>\" and x == \"</s>\")):\n",
    "                precedeCount = precedeCount + 1\n",
    "                continue\n",
    "            if(x == '<s>' or precedeCount == 5 or (precede == \"</s>\" and x == \"</s>\") ):\n",
    "                #print(\"Stop because: \" + str(precede))\n",
    "                break\n",
    "            for y in datasetStemmed:\n",
    "                if(y[1] == x and y[0] == precede):\n",
    "                    print(y[0] + y[1])\n",
    "                    biCount = biCount + 1\n",
    "            if(uniCount != 0):\n",
    "                if(precede == \"<s>\"):\n",
    "                    Matrix[4][assignColumn] = biCount/uniCount\n",
    "                if(precedeCount != 4):\n",
    "                    Matrix[precedeCount][assignColumn] = biCount/uniCount\n",
    "            elif (biCount == 0  and uniCount == 0): \n",
    "                 Matrix[precedeCount][assignColumn] = -1\n",
    "            else:\n",
    "                Matrix[precedeCount][assignColumn] = 0\n",
    "            print( precede +  \"  \" + x + \":\" + str(Matrix[precedeCount][assignColumn]))\n",
    "            precedeCount = precedeCount + 1\n",
    "            \n",
    "                \n",
    "    assignColumn = assignColumn + 1\n",
    "    uniCount = 0\n",
    "    biCount = 0\n",
    "    for i in range(w):\n",
    "        print(\"Column \")\n",
    "        for j in range(h):\n",
    "            print(str(Matrix[i][j]) + \" \")\n",
    "    \n",
    "    print\n",
    "\n",
    "    #fix the UNK a = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===UNIGRAM MODEL===\n",
      "- Unsmoothed -\n",
      " a: 0.26666666666666666 b: 0.3333333333333333 c: 0.4\n",
      "- Smoothed -\n",
      " a: 0.2777777777777778 b: 0.3333333333333333 c: 0.3888888888888889\n",
      "===BIGRAM MODEL===\n",
      "- Unsmoothed -\n",
      "<s>a\n",
      "<s>a\n",
      "<s>  a:0.5\n",
      "aa\n",
      "a  a:0.25\n",
      "b  a:0.0\n",
      "ca\n",
      "c  a:0.25\n",
      "UNK  a:0.5\n",
      "<s>b\n",
      "<s>  b:0.1111111111111111\n",
      "ab\n",
      "ab\n",
      "a  b:0.2222222222222222\n",
      "bb\n",
      "b  b:0.1111111111111111\n",
      "cb\n",
      "c  b:0.1111111111111111\n",
      "UNK  b:0.1111111111111111\n",
      "<s>  c:0.0\n",
      "ac\n",
      "a  c:0.06666666666666667\n",
      "bc\n",
      "bc\n",
      "bc\n",
      "b  c:0.2\n",
      "cc\n",
      "cc\n",
      "c  c:0.13333333333333333\n",
      "UNK  c:0.0\n",
      "<s>  UNK:0.0\n",
      "a  UNK:0.0\n",
      "b  UNK:0.0\n",
      "c  UNK:0.0\n",
      "UNK  UNK:0.0\n",
      "a  </s>:0.0\n",
      "b</s>\n",
      "b  </s>:0.05555555555555555\n",
      "c</s>\n",
      "c</s>\n",
      "c  </s>:0.1111111111111111\n",
      "UNK  </s>:0.0\n",
      "Column \n",
      "0.0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "Column \n",
      "0.0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "Column \n",
      "0.05555555555555555 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "Column \n",
      "0.1111111111111111 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "Column \n",
      "0.0 \n",
      "0 \n",
      "0 \n",
      "0 \n",
      "0 \n"
     ]
    }
   ],
   "source": [
    "import nltk.tokenize\n",
    "import re\n",
    "dataset = open('a01_data\\sampledata.txt', 'r')\n",
    "vocabulary = open('a01_data\\sampledata.vocab.txt', 'r')\n",
    "datasetTemp = dataset.read()\n",
    "scrappedSentence = re.sub(r'[<][s][>] | [<][/][s][>]', ' ', datasetTemp)\n",
    "datasetStemmed = WhitespaceTokenizer().tokenize(scrappedSentence)\n",
    "vocabularyStemmed = word_tokenize(vocabulary.read())\n",
    "print('===UNIGRAM MODEL===')\n",
    "unigramOriginal(datasetStemmed, vocabularyStemmed)\n",
    "unigramSmoothed(datasetStemmed, vocabularyStemmed)\n",
    "\n",
    "print('\\n'+ '===BIGRAM MODEL===')\n",
    "vocabularyStemmed.insert(0,\"<s>\")\n",
    "vocabularyStemmed.append(\"UNK\")\n",
    "vocabularyStemmed.append(\"</s>\")\n",
    "datasetStemmed = WhitespaceTokenizer().tokenize(datasetTemp)\n",
    "bigram = list(nltk.bigrams(datasetStemmed))\n",
    "bigram.remove(('</s>', '<s>'))\n",
    "bigram.remove(('</s>', '<s>'))\n",
    "bigramOriginal(bigram,vocabularyStemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
